Title           : Performance Analysis of Kafka Backed Stream Processing 
Title Note      : Draft, &date; (version 0.1)
Author          : [Milinda Pathirage](http://milinda.pathirage.org)
Affiliation     : School of Informatics and Computing, Indiana University
Bib             : bibliography
Cite All        : False
Colorizer       : kokax.json
Logo            : False
Css             : https://fonts.googleapis.com/css?family=Crimson+Text
Revision        : 0.1
Package         : tikz
Package         : rotating
Package         : float
Package         : pgfgantt
Package         : enumitem
Package         : amssymb
Package         : bm
Package         : pifont
Tex Header      : \newlist{todolist}{itemize}{2}
                  \setlist[todolist]{label=$\square$}
                  \newcommand{\cmark}{\ding{51}}%
                  \newcommand{\xmark}{\ding{55}}%
                  \newcommand{\done}{\rlap{$\square$}{\raisebox{2pt}{\large\hspace{1pt}\cmark}}%
                  \hspace{-2.5pt}}
                  \newcommand{\wontfix}{\rlap{$\square$}{\large\hspace{1pt}\xmark}}



@if not tex {
  .madoko {
font-family: 'Crimson Text', serif;
    font-size: 18px;
  }
}


[TITLE]

~Abstract
Apache Kafka is widely used distributed and decentralized pub-sub system. Most stream processing and data integration deployments use Apache Kafka as the messaging layer. This paper propose a performance model for Apache Kafka that can use to reason about stream processing infrastructure performance as well as resource planning for data integration and stream processing architecture.
~

# Basics of Analytical Modeling

## Single-Server Network

Simplest queueing network is **single-server network** shown below in Figure [#fig-singleserver]. Here $\lambda$ is the average arrival rate while
$\mu$ is average service rate. $\lambda < \mu$ is required to maintain the system stability, queue length will go to infinity if $\lambda \geq \mu$.

~ Figure { #fig-singleserver; caption: "Single-Server Network" }
~~ Snippet
\begin{tikzpicture}[>=latex]
% the rectangle with vertical rules
\draw (0,0) -- ++(2cm,0) -- ++(0,-1.5cm) -- ++(-2cm,0);
\foreach \i in {1,...,4}
  \draw (2cm-\i*10pt,0) -- +(0,-1.5cm);

% the circle
\draw (2.75,-0.75cm) circle [radius=0.75cm];

% the arrows and labels
\draw[->] (3.5,-0.75) -- +(20pt,0);
\draw[<-] (0,-0.75) -- +(-20pt,0) node[left] {$\lambda$};
\node at (2.75,-0.75cm) {$\mu$};
\node[align=center] at (1cm,-2cm) {Waiting \\ Area};
\node[align=center] at (3cm,-2cm) {Service \\ Node};
\end{tikzpicture}
~~
~

**Device utilizaiton** ($\rho$) is the *fraction of time the device is busy*. When $\lambda < \mu$,

~ Math
\rho = \frac{\lambda}{\mu}
~

**Device throughput** ($X$) is the *rate of completions at the device*. When $\lambda < \mu$,

~ Math
X = \rho \cdot \mu = \frac{\lambda}{\mu} \cdot \mu = \lambda
~ 

$\mu$ is the maximum possible throughput $X$.

## Ergodic System

A system that is positive recurrent, aperiodic, and irreducible.

* **Irreducibility:** Process should be able to get from any state to any other state. This is important for ensuring that the choice of initial state does not matter.
* **Positive Recurrent:** Important for understanding the equivalence of the time average and the ensemble average. *Given an irreducible system, in whihc we can get to any state, the system is positive recurrent if for any state $i$, the state us revisited infinitely often, and the mean time between visits of state $i$ is finite. Furthermore, every time that we visit state $i$ the system will probabilistically restart itself. (Example number of jobs in the system becomes zero)
* **Aperiodic:** Refers to the fact that the system state should not be tied in some particular way to the time step; for example, it should not be the case that the system is always in state 0 for even time steps and state 1 for odd time steps.

## Little's Law for Open Systems

For any ergodic open system we have that

~ Math
\mathbf{E}[N] = \lambda \mathbf{E}[T]
~

where $\mathbf{E}[N]$ is the expected number of jobs in the system, $\lambda$ is the average arrival rate into the system, and $\mathbf{E}[T]$ is the mean time jobs spend in the system.

> Little's Law makes no assumptions about the arrival process, the service time distribution at the servers, the network topology, the service order, or anything!

### Intutions and Corollaries

## Forced Flow Law

Relates system throughput to the throupghput of an individual device as follows:

~ Math
X_i = \mathbf{E}[V_i] \cdot X
~ 

where $X$ denotes the system throughput, $X_i$ denotes the throughput at device $i$, and $V_i$ denotes the number of visits to device $i$ per job.

# Notes

* What performance aspects of Kafka we need to cover?
  - Reliability
  - Speed
  - Economicity
* What metrics we should measure?
  - Latency: At producer, at consumer, end-to-end latency
  - Throughput: From the perspective of producer as well as consumer
  - CPU, Memory and Disk usage: At broker
* What kind of workloads to consider?
  - This is an open question
* A basic framework (analytical model) to reason about Kafka's performance behaviour based on above metrics
* Benchmarking framework
* Workloads should be related to Kafka backed data management system (Database)

# Kafka in Cloud

From [Kafka Inside Keystone Pipeline](http://techblog.netflix.com/2016/04/kafka-inside-keystone-pipeline.html)

* Unpredictable instance life-cycles and termination due to hardware failures
* Transient network issues

> These are not problems for stateless services but pose a big challenge for a stateful service requiring ZooKeeper and a single controller for coordination. 

* Outlier brokers: uneven workload, hardware problems, or specific environment problems such as noisy neighbours due to multi-tenancy.
* Outlier brokers have intermittent slow responses or frequent TCP timeouts and retransmissions
* Producers who produce to outlier broker may exhaust its local buffers while waiting for responses
* Kafka 0.8.2 doesn't support timeout for messages waiting in producer buffer
* Kafka replication leads to inter-dependencies among brokers and outlier brokers can cause cascading effect.
* If an outlier slows down replication, replication lag may build up and eventually cause partition leaders to read from disk to serve the application requests. This slows down the effected brokers and may cause message drops at producers due to buffer exhaust.

## Deployment strategies for cloud 

* Multiple smaller cluster instead of one giant cluster. Reduces operational complexity. (Largest with 200 brokers) 
* Limit the number of partitions in each cluster. Less than 10,000. Improves availability and reduces the latency for requests/responses that are bound to the number partitions.
* Even distribution of replicas for each topic. Make it easy to perform capacity planning and detection of outliers.
* Dedicated Zookeeper cluster for each Kafka cluster.

## Important metrics

* Brokers ability to receive and deliver messages using heartbeat messages and latency
* Samza checkpointed offset and broker's log offset to measure Samza lag

## Future

* Tiered SLAs for topics
* Topics that can accept minor loss configured to 1 replica. Absence of replication saves bandwidth and minimize state changes that have to depend on the controller

# Basic Model for Samza

A Samza job is a set of stream tasks $ST$ that process messages from one or more topic partitions belonging to one or more topics.

# Basic Model for Kafka

A Kafka cluster is a set of borkers $B$ that hosts a set of topics $T$. A topic $t~(t \in T)$ is partitioned into $n$ partitions $(P)$ and each partition $p~(p \in P)$ is replicated [@kafkawiki:reptools] $m$ times for fault tolerance and availability. Each replica $r$ of a partition $p$ of topic $t$ get assigned to a broker $b~(b \in B)$ at topic creation and replica may get assigned to a different broker due to broker failures or partition reassignment [@kafkawiki:reptools].

## Replication Sets

We can consider a replication set as a physical view of a partition which is a logical concept of Kafka.

* $R_{tp}$ is a set of replicas for a partition $p$ of topic $t$ and often referred to as *assigned replicas* in Kafka literature. 
* Each replica set has a leader replica (often this is also the preffered replica) and a set of follower replicas $(R_{tp} = \{r_l\} \cup \{r_{f0},r_{f1},...,r_{fn}\})$. 
* A topic $t$ is a collection of replica sets (partitions) $(t = \bigcup_{i=1}^{n} R_{ti} )$

## Replica Assignment Problem

Let's define variables first:

~ Equation {#broker-capacity}
\begin{aligned}
 y_i =
  \begin{cases}
    1       & \quad \text{if broker } i \text{ is at capacity}\\
    0       & \quad \text{otherwise}\\
  \end{cases}
\end{aligned}
~

~ Equation {#membership}
\begin{aligned}
 x_{ki} =
  \begin{cases}
    1       & \quad \text{if replica } k \text{ is assigned to broker } i\\
    0       & \quad \text{otherwise}\\
  \end{cases}
\end{aligned}
~

For better resource utilization, we should try to minimize the number of brokers used to host topics.

~ Equation {#minimization}
\begin{aligned}
 min \displaystyle\sum_{i=1}^{a} y_i 
\end{aligned}
~

Assuming we have $l$ topics, we should assign $\displaystyle\sum_{i=1}^{l} n_l \times m_l $ number of replicas into a set of brokers while maximizing resource utilization. Here $n_l$ is the number of partitions in topic $l$ and $m_l$ is the replication factor of topic $l$.

Folloing contraints should be considered when assigning replicas to brokers:

* Per broker disk capacity and disk capacity each replica will consume.
* Per broker network capacity
* Topic retention policy (The capacity of a replica will depends on retension poilcy directly. Message rate and dstribution of messages accross partitions will effect replica size in case of time based retention.)
* Also two or more replicas from the same replica set cannot be assigned to same broker.

Let $cr_k$ be the capacity of replica $k$, $cb_i$ be the capacity of broker $i$, and $cn_i$ be the network capacity of broker $i$. Let $\sigma_{ki}$ be the throughput of replica $k$ in broker $i$.

~Equation {#capacity-constraint}
\begin{aligned}
\forall i \displaystyle\sum_{k=1}^{n} cr_k x_{ki} \le cb_i y_i 
\end{aligned}
~

~Equation {#assignment-constraint}
\begin{aligned}
\forall k \displaystyle\sum_{i=1}^{a} x_{ki} = 1 
\end{aligned}
~

~Equation {#colocating-constraint}
\forall r \in R_{tp}: ~  r \in b \iff (R_{tp} \setminus \{r\}) \notin b
~

~Equation {#network-constraint}
\begin{aligned}
\forall i \displaystyle\sum_{k=1}^{n} \sigma_{ki} \le cn_i 
\end{aligned}
~

## Throughput Model

* Multiple replicas are assigned to same broker. Some of these may be from same topic.
* Can preffered replicas get assigned to same broker.
* Multiple replicas may be competing for broker resources
* How replication effect throughput

## Latency Model

* How replication effect latency

## Consumer Lag Model


# Basic Performance Tests

* Impact of the number of producers
* Impact of the number of servers
* Impact of the message size
* Impact of the number topics
* Impact of the number of partitions
* Impact of replication
* Impact of replaying

# TODO

~ Comment
  \begin{todolist}
  \item[\done] Workload generator task for FDBench
  \item Write solution
  \item[\wontfix] profit
  \end{todolist}
~

~ Snippet
\begin{itemize}
  \item Immediate plan of action.
  \begin{todolist}
  \item Workload generator task for FDBench
  \item Understand relationship between Kafka partition count and read throughput
  \item Throughput measuring tasks for FDBench
  \end{todolist}
\end{itemize}
~




[BIB]
 