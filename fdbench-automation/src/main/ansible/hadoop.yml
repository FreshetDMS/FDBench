---
- name: Create Hadoop EC2 security group
  hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - name: Create security group
      ec2_group:
        name: "{{ ec2.hadoop_security_group }}"
        description: EC2 security group for Hadoop
        region: "{{ ec2.region }}"
        rules:
          - proto: tcp
            from_port: 22
            to_port: 22
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 8000
            to_port: 8200
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 50000
            to_port: 50500
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 8400
            to_port: 8500
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 10000
            to_port: 10500
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 0
            to_port: 65535
            cidr_ip: 172.16.0.0/12
        rules_egress:
          - proto: tcp
            from_port: 0
            to_port: 65535
            cidr_ip: 0.0.0.0/0

- name: Create EC2 instance for Hadoop master
  hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - name: Launch instances
      ec2:
        key_name: "{{ ec2.key }}"
        group: "{{ ec2.hadoop_security_group }}"
        instance_type: "{{ ec2.hadoop_master_instance_type }}"
        image: "{{ ec2.image }}"
        wait: yes
        region: "{{ ec2.region }}"
        count: 1
        spot_price: "{{ ec2.hadoop_spot_price }}"
        spot_wait_timeout: 1200
      register: hadoop_master
    - name: Add new instances to a hosts group
      add_host: name={{ item.1.public_dns_name }} groups=hadoopmaster zid={{ item.0 + 1 }} private_ip={{ item.1.private_ip }} instance_type={{ item.1.instance_type }} hadoop_node_type=master
      with_indexed_items: "{{ hadoop_master.instances }}"
    - name: Wait for SSH to come up
      wait_for: host={{ item.public_dns_name }} port=22 delay=60 timeout=360 state=started
      with_items: "{{ hadoop_master.instances }}"
    - name: Make sure the known hosts file exists
      file: "path={{ ssh_known_hosts_file }} state=touch"
    - name: Check hosts name availability
      shell: "ssh-keygen -f {{ ssh_known_hosts_file }} -F {{ item.public_dns_name }}"
      with_items: "{{ hadoop_master.instances }}"
      register: h_ssh_known_host_results
      ignore_errors: yes
    - name: Scan the public key
      shell: "{{ ssh_known_hosts_command}} {{ item.item.public_dns_name }} >> {{ ssh_known_hosts_file }}"
      with_items: "{{ h_ssh_known_host_results.results }}"
      when: item.stdout == ""
    - name: Adding ec2 instance as host for running python 2 install
      add_host:
        group: hm_ec2_hosts
        name: "{{ item.public_dns_name }}"
        ansible_host: "{{ item.public_ip }}"
        ansible_port: 22
        ansible_user: ubuntu
        ansible_private_key_file: "{{ ec2.key_file }}"
      with_items: "{{ hadoop_master.instances }}"
    - name: Installing python
      delegate_to: "{{ item }}"
      raw: test -e /usr/bin/python || (sudo apt -y update && sudo apt install -y python-minimal)
      with_items: "{{ groups['hm_ec2_hosts'] }}"

- name: Install JDK and Hadoop common
  hosts: hadoopmaster
  remote_user: ubuntu
  become: true
  become_method: sudo
  gather_facts: yes
  roles:
    - jdk
    - hadoop_common
    - hadoop_master_slaves

- name: Setup Hadoop master
  hosts: hadoopmaster
  remote_user: ubuntu
  become_user: "{{ hadoop.user }}"
  become: yes
  become_method: sudo
  gather_facts: yes
  roles:
    - hadoop_master

- name: Create EC2 instances for Hadoop slaves
  hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - name: Launch instances
      ec2:
        key_name: "{{ ec2.key }}"
        group: "{{ ec2.hadoop_security_group }}"
        instance_type: "{{ ec2.hadoop_slave_instance_type }}"
        image: "{{ ec2.image }}"
        wait: yes
        region: "{{ ec2.region }}"
        count: "{{ ec2.hadoop_slave_count }}"
        spot_price: "{{ ec2.hadoop_spot_price }}"
        spot_wait_timeout: 1200
      register: hadoop_slaves
    - name: Add new instances to a hosts group
      add_host: name={{ item.1.public_dns_name }} groups=hadoopslaves zid={{ item.0 + 1 }} private_ip={{ item.1.private_ip }} instance_type={{ item.1.instance_type }} hadoop_node_type=slave
      with_indexed_items: "{{ hadoop_slaves.instances }}"
    - name: Wait for SSH to come up
      wait_for: host={{ item.public_dns_name }} port=22 delay=60 timeout=360 state=started
      with_items: "{{ hadoop_slaves.instances }}"
    - name: Make sure the known hosts file exists
      file: "path={{ ssh_known_hosts_file }} state=touch"
    - name: Check hosts name availability
      shell: "ssh-keygen -f {{ ssh_known_hosts_file }} -F {{ item.public_dns_name }}"
      with_items: "{{ hadoop_slaves.instances }}"
      register: hs_ssh_known_host_results
      ignore_errors: yes
    - name: Scan the public key
      shell: "{{ ssh_known_hosts_command}} {{ item.item.public_dns_name }} >> {{ ssh_known_hosts_file }}"
      with_items: "{{ hs_ssh_known_host_results.results }}"
      when: item.stdout == ""
    - name: Adding ec2 instance as host for running python 2 install
      add_host:
        group: hs_ec2_hosts
        name: "{{ item.public_dns_name }}"
        ansible_host: "{{ item.public_ip }}"
        ansible_port: 22
        ansible_user: ubuntu
        ansible_private_key_file: "{{ ec2.key_file }}"
      with_items: "{{ hadoop_slaves.instances }}"
    - name: Installing python
      delegate_to: "{{ item }}"
      raw: test -e /usr/bin/python || (sudo apt -y update && sudo apt install -y python-minimal)
      with_items: "{{ groups['hs_ec2_hosts'] }}"


- name: Install JDK and Hadoop common
  hosts: hadoopslaves
  remote_user: ubuntu
  become: true
  become_method: sudo
  gather_facts: yes
  roles:
    - jdk
    - hadoop_common

- name: Setup Hadoop slave
  hosts: hadoopslaves
  remote_user: ubuntu
  become_user: "{{ hadoop.user }}"
  become: yes
  become_method: sudo
  gather_facts: yes
  roles:
    - hadoop_slave

- name: Copy Hadoop configuration
  hosts: localhost
  connection: local
  gather_facts: no
  roles:
    - hadoop_conf
